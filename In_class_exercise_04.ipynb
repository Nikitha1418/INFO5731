{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "In_class_exercise_04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikitha1418/INFO5731/blob/master/In_class_exercise_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EuX00KHNeSpw"
      },
      "source": [
        "# **The fourth in-class-exercise (20 points in total)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s-vTOb03hG1f"
      },
      "source": [
        "# 1. Text Data Preprocessing\n",
        "\n",
        "Here is a [legal case](https://github.com/unt-iialab/INFO5731_FALL2020/blob/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt) we collected from westlaw, please follow the steps we mentioned in lesson 5 to clean the data:\n",
        "\n",
        "\n",
        "\n",
        "## 1.1 Basic feature extraction using text data (4 points)\n",
        "\n",
        "*   Number of sentences\n",
        "*   Number of words\n",
        "*   Number of characters\n",
        "*   Average word length\n",
        "*   Number of stopwords\n",
        "*   Number of special characters\n",
        "*   Number of numerics\n",
        "*   Number of uppercase words\n",
        "\n",
        "## 1.2 Basic Text Pre-processing of text data (4 points)\n",
        "\n",
        "*   Lower casing\n",
        "*   Punctuation removal\n",
        "*   Stopwords removal\n",
        "*   Frequent words removal\n",
        "*   Rare words removal\n",
        "*   Spelling correction\n",
        "*   Tokenization\n",
        "*   Stemming\n",
        "*   Lemmatization\n",
        "\n",
        "## 1.3 Save all the **clean sentences** to a **csv file** (one column, each raw is a sentence) after finishing all the steps above. (4 points)\n",
        "\n",
        "\n",
        "## 1.4 Advance Text Processing (Extra credit: 4 points)\n",
        "\n",
        "*   Calculate the term frequency of all the terms.\n",
        "*   Print out top 10 1-gram, top 10 2-grams, and top 10 3-grams terms as features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vR0L3_CreM_A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "f11ca7e2-41a5-4cec-e532-8a0831c9fa58"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib\n",
        "array_text = []\n",
        "input_file = urllib.request.urlopen(\"https://raw.githubusercontent.com/unt-iialab/INFO5731_FALL2020/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt\")\n",
        "for i in input_file:\n",
        "  data = i.decode(\"utf-8\")\n",
        "  clean_data = data.replace('\\r\\n', '')\n",
        "  if clean_data:\n",
        "    array_text.append(clean_data)\n",
        "input_data = pd.DataFrame(array_text, columns = ['Text'])\n",
        "print(input_data)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Text\n",
            "0                                           5 Ala. 740\n",
            "1                            Supreme Court of Alabama.\n",
            "2                                                ADAMS\n",
            "3                                                   v.\n",
            "4                                   TANNER AND HORTON.\n",
            "..                                                 ...\n",
            "143            There are no Filings for this citation.\n",
            "144                                 Negative Treatment\n",
            "145  There are no Negative Treatment results for th...\n",
            "146                                            History\n",
            "147    There are no History results for this citation.\n",
            "\n",
            "[148 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpmxPRLq3cu4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "d599c338-c21c-4deb-be59-5fadc12c78d5"
      },
      "source": [
        "#Number of Sentences\n",
        "\n",
        "input_data['Sentences'] = input_data['Text'].apply(lambda x: len(str(x).split(\".\")))\n",
        "print(input_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>There are no Filings for this citation.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>Negative Treatment</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>There are no Negative Treatment results for th...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>History</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>There are no History results for this citation.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>148 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text  Sentences\n",
              "0                                           5 Ala. 740          2\n",
              "1                            Supreme Court of Alabama.          2\n",
              "2                                                ADAMS          1\n",
              "3                                                   v.          2\n",
              "4                                   TANNER AND HORTON.          2\n",
              "..                                                 ...        ...\n",
              "143            There are no Filings for this citation.          2\n",
              "144                                 Negative Treatment          1\n",
              "145  There are no Negative Treatment results for th...          2\n",
              "146                                            History          1\n",
              "147    There are no History results for this citation.          2\n",
              "\n",
              "[148 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpw3XM-W3oXy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "e55fcb62-bfbd-42c5-e2da-a31b00f93fec"
      },
      "source": [
        "#Number of Words\n",
        "\n",
        "input_data['Words'] = input_data['Text'].apply(lambda x: len(str(x).split(\" \")))\n",
        "print(input_data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Text  Sentences  Words\n",
            "0                                           5 Ala. 740          2      3\n",
            "1                            Supreme Court of Alabama.          2      4\n",
            "2                                                ADAMS          1      1\n",
            "3                                                   v.          2      1\n",
            "4                                   TANNER AND HORTON.          2      3\n",
            "..                                                 ...        ...    ...\n",
            "143            There are no Filings for this citation.          2      7\n",
            "144                                 Negative Treatment          1      2\n",
            "145  There are no Negative Treatment results for th...          2      9\n",
            "146                                            History          1      1\n",
            "147    There are no History results for this citation.          2      8\n",
            "\n",
            "[148 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcFZMbH13x-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "3fd7e0ba-211a-49a4-a321-abf54f8e3efa"
      },
      "source": [
        "#Number of Characters\n",
        "\n",
        "input_data['Characters'] = input_data['Text'].str.len()\n",
        "print(input_data)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Text  ...  Characters\n",
            "0                                           5 Ala. 740  ...          10\n",
            "1                            Supreme Court of Alabama.  ...          25\n",
            "2                                                ADAMS  ...           5\n",
            "3                                                   v.  ...           2\n",
            "4                                   TANNER AND HORTON.  ...          18\n",
            "..                                                 ...  ...         ...\n",
            "143            There are no Filings for this citation.  ...          39\n",
            "144                                 Negative Treatment  ...          18\n",
            "145  There are no Negative Treatment results for th...  ...          58\n",
            "146                                            History  ...           7\n",
            "147    There are no History results for this citation.  ...          47\n",
            "\n",
            "[148 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3_3RlMs382i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "034fc8b7-f285-46a7-ca46-df66ce94916e"
      },
      "source": [
        "#Avereage Word Length\n",
        "\n",
        "def avg_word(sentence):\n",
        "  words = sentence.split()\n",
        "  if len(words) != 0:\n",
        "    return(sum(len(word) for word in words)/len(words))\n",
        "  else:\n",
        "    return None\n",
        "input_data['Word_Length'] = input_data['Text'].apply(lambda x: avg_word(x))\n",
        "print(input_data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Text  ...  Word_Length\n",
            "0                                           5 Ala. 740  ...     2.666667\n",
            "1                            Supreme Court of Alabama.  ...     5.500000\n",
            "2                                                ADAMS  ...     5.000000\n",
            "3                                                   v.  ...     2.000000\n",
            "4                                   TANNER AND HORTON.  ...     5.333333\n",
            "..                                                 ...  ...          ...\n",
            "143            There are no Filings for this citation.  ...     4.714286\n",
            "144                                 Negative Treatment  ...     8.500000\n",
            "145  There are no Negative Treatment results for th...  ...     5.555556\n",
            "146                                            History  ...     7.000000\n",
            "147    There are no History results for this citation.  ...     5.000000\n",
            "\n",
            "[148 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrYiccN24GFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "c3e212aa-92eb-4cc4-ae32-ec6d171b16a2"
      },
      "source": [
        "#Number of StopWords\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "input_data['Stopwords'] = input_data['Text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
        "print(input_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "                                                  Text  ...  Stopwords\n",
            "0                                           5 Ala. 740  ...          0\n",
            "1                            Supreme Court of Alabama.  ...          1\n",
            "2                                                ADAMS  ...          0\n",
            "3                                                   v.  ...          0\n",
            "4                                   TANNER AND HORTON.  ...          0\n",
            "..                                                 ...  ...        ...\n",
            "143            There are no Filings for this citation.  ...          4\n",
            "144                                 Negative Treatment  ...          0\n",
            "145  There are no Negative Treatment results for th...  ...          4\n",
            "146                                            History  ...          0\n",
            "147    There are no History results for this citation.  ...          4\n",
            "\n",
            "[148 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BbSrOOlWwSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def special_characters_count(given_input):\n",
        "  number_of_special_characters = 0\n",
        "  for i in range(len(given_input)):\n",
        "    if not((given_input[i].isalpha()) and (given_input[i].isdigit())):\n",
        "        number_of_special_characters = number_of_special_characters + 1\n",
        "  return number_of_special_characters"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CEhHoZg4UvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "f6359fb2-6fe9-4cfb-8df6-bde07a6834f0"
      },
      "source": [
        "#Number of special characters\n",
        "input_data['Special characters'] = input_data['Text'].apply(lambda x: special_characters_count(x))\n",
        "print(input_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Text  ...  Special characters\n",
            "0                                           5 Ala. 740  ...                  10\n",
            "1                            Supreme Court of Alabama.  ...                  25\n",
            "2                                                ADAMS  ...                   5\n",
            "3                                                   v.  ...                   2\n",
            "4                                   TANNER AND HORTON.  ...                  18\n",
            "..                                                 ...  ...                 ...\n",
            "143            There are no Filings for this citation.  ...                  39\n",
            "144                                 Negative Treatment  ...                  18\n",
            "145  There are no Negative Treatment results for th...  ...                  58\n",
            "146                                            History  ...                   7\n",
            "147    There are no History results for this citation.  ...                  47\n",
            "\n",
            "[148 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRxYrxeK4dt7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "ad19d590-e05d-4af0-c020-e64775500d43"
      },
      "source": [
        "#Number of Numerics\n",
        "\n",
        "input_data['Numerics'] = input_data['Text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
        "print(input_data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Text  ...  Numerics\n",
            "0                                           5 Ala. 740  ...         2\n",
            "1                            Supreme Court of Alabama.  ...         0\n",
            "2                                                ADAMS  ...         0\n",
            "3                                                   v.  ...         0\n",
            "4                                   TANNER AND HORTON.  ...         0\n",
            "..                                                 ...  ...       ...\n",
            "143            There are no Filings for this citation.  ...         0\n",
            "144                                 Negative Treatment  ...         0\n",
            "145  There are no Negative Treatment results for th...  ...         0\n",
            "146                                            History  ...         0\n",
            "147    There are no History results for this citation.  ...         0\n",
            "\n",
            "[148 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouaMHEnL4oC-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "d7109723-d7f1-42e7-910a-413932edd410"
      },
      "source": [
        "#Number of UpperCase Words\n",
        "\n",
        "input_data['Upper case words'] = input_data['Text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
        "print(input_data)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Text  ...  Upper case words\n",
            "0                                           5 Ala. 740  ...                 0\n",
            "1                            Supreme Court of Alabama.  ...                 0\n",
            "2                                                ADAMS  ...                 1\n",
            "3                                                   v.  ...                 0\n",
            "4                                   TANNER AND HORTON.  ...                 3\n",
            "..                                                 ...  ...               ...\n",
            "143            There are no Filings for this citation.  ...                 0\n",
            "144                                 Negative Treatment  ...                 0\n",
            "145  There are no Negative Treatment results for th...  ...                 0\n",
            "146                                            History  ...                 0\n",
            "147    There are no History results for this citation.  ...                 0\n",
            "\n",
            "[148 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQjQbGZs4y4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "1e41eb12-3513-436b-dafe-358b67271bd4"
      },
      "source": [
        "#Number of Lower Case\n",
        "\n",
        "input_data['Lower Case words'] = input_data['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "print(input_data)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Text  ...                                   Lower Case words\n",
            "0                                           5 Ala. 740  ...                                         5 ala. 740\n",
            "1                            Supreme Court of Alabama.  ...                          supreme court of alabama.\n",
            "2                                                ADAMS  ...                                              adams\n",
            "3                                                   v.  ...                                                 v.\n",
            "4                                   TANNER AND HORTON.  ...                                 tanner and horton.\n",
            "..                                                 ...  ...                                                ...\n",
            "143            There are no Filings for this citation.  ...            there are no filings for this citation.\n",
            "144                                 Negative Treatment  ...                                 negative treatment\n",
            "145  There are no Negative Treatment results for th...  ...  there are no negative treatment results for th...\n",
            "146                                            History  ...                                            history\n",
            "147    There are no History results for this citation.  ...    there are no history results for this citation.\n",
            "\n",
            "[148 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2tv9Mpm46e5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "17cc5109-c73a-4172-a308-31ffd318dfb9"
      },
      "source": [
        "#Removal of Punctuations\n",
        "\n",
        "input_data['Punctuation'] = input_data['Lower Case words'].str.replace('[^\\w\\s]','')\n",
        "print(input_data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Text  ...                                        Punctuation\n",
            "0                                           5 Ala. 740  ...                                          5 ala 740\n",
            "1                            Supreme Court of Alabama.  ...                           supreme court of alabama\n",
            "2                                                ADAMS  ...                                              adams\n",
            "3                                                   v.  ...                                                  v\n",
            "4                                   TANNER AND HORTON.  ...                                  tanner and horton\n",
            "..                                                 ...  ...                                                ...\n",
            "143            There are no Filings for this citation.  ...             there are no filings for this citation\n",
            "144                                 Negative Treatment  ...                                 negative treatment\n",
            "145  There are no Negative Treatment results for th...  ...  there are no negative treatment results for th...\n",
            "146                                            History  ...                                            history\n",
            "147    There are no History results for this citation.  ...     there are no history results for this citation\n",
            "\n",
            "[148 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKXdw46e5Fz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "6457ac75-a1c6-4ea5-aa1e-c638f6aee2b9"
      },
      "source": [
        "#Removal of StopWords\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "input_data['removed stopwords'] = input_data['Punctuation'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "print(input_data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Text  ...                    removed stopwords\n",
            "0                                           5 Ala. 740  ...                            5 ala 740\n",
            "1                            Supreme Court of Alabama.  ...                supreme court alabama\n",
            "2                                                ADAMS  ...                                adams\n",
            "3                                                   v.  ...                                    v\n",
            "4                                   TANNER AND HORTON.  ...                        tanner horton\n",
            "..                                                 ...  ...                                  ...\n",
            "143            There are no Filings for this citation.  ...                     filings citation\n",
            "144                                 Negative Treatment  ...                   negative treatment\n",
            "145  There are no Negative Treatment results for th...  ...  negative treatment results citation\n",
            "146                                            History  ...                              history\n",
            "147    There are no History results for this citation.  ...             history results citation\n",
            "\n",
            "[148 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUCZG3Z35Ojz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "c945de6f-3dc8-4d8f-d254-4b9832e7ebc1"
      },
      "source": [
        "#Common Words Removal\n",
        "\n",
        "frequent_words = pd.Series(' '.join(input_data['removed stopwords']).split()).value_counts()[:10]\n",
        "print(frequent_words)\n",
        "frequent_words = list(frequent_words.index)\n",
        "input_data['Removal of Common Words'] = input_data['removed stopwords'].apply(lambda x: \" \".join(x for x in x.split() if x not in frequent_words))\n",
        "print(input_data)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "execution    50\n",
            "crop         49\n",
            "lien         25\n",
            "levy         25\n",
            "claimants    22\n",
            "v            22\n",
            "case         21\n",
            "right        21\n",
            "court        20\n",
            "gathered     19\n",
            "dtype: int64\n",
            "                                                  Text  ...              Removal of Common Words\n",
            "0                                           5 Ala. 740  ...                            5 ala 740\n",
            "1                            Supreme Court of Alabama.  ...                      supreme alabama\n",
            "2                                                ADAMS  ...                                adams\n",
            "3                                                   v.  ...                                     \n",
            "4                                   TANNER AND HORTON.  ...                        tanner horton\n",
            "..                                                 ...  ...                                  ...\n",
            "143            There are no Filings for this citation.  ...                     filings citation\n",
            "144                                 Negative Treatment  ...                   negative treatment\n",
            "145  There are no Negative Treatment results for th...  ...  negative treatment results citation\n",
            "146                                            History  ...                              history\n",
            "147    There are no History results for this citation.  ...             history results citation\n",
            "\n",
            "[148 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY4quxEE5czF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "e703971d-cbf0-4d65-fbd1-541f28aa267c"
      },
      "source": [
        "#Rare Words Removal\n",
        "\n",
        "rare = pd.Series(' '.join(input_data['removed stopwords']).split()).value_counts()[-10:]\n",
        "print(rare)\n",
        "rare = list(rare.index)\n",
        "input_data['removed rare words'] = input_data['Removal of Common Words'].apply(lambda x: \" \".join(x for x in x.split() if x not in rare))\n",
        "print(input_data)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "resided       1\n",
            "require       1\n",
            "attempted     1\n",
            "inquire       1\n",
            "31            1\n",
            "368           1\n",
            "307           1\n",
            "hurtell       1\n",
            "bona          1\n",
            "interfered    1\n",
            "dtype: int64\n",
            "                                                  Text  ...                   removed rare words\n",
            "0                                           5 Ala. 740  ...                            5 ala 740\n",
            "1                            Supreme Court of Alabama.  ...                      supreme alabama\n",
            "2                                                ADAMS  ...                                adams\n",
            "3                                                   v.  ...                                     \n",
            "4                                   TANNER AND HORTON.  ...                        tanner horton\n",
            "..                                                 ...  ...                                  ...\n",
            "143            There are no Filings for this citation.  ...                     filings citation\n",
            "144                                 Negative Treatment  ...                   negative treatment\n",
            "145  There are no Negative Treatment results for th...  ...  negative treatment results citation\n",
            "146                                            History  ...                              history\n",
            "147    There are no History results for this citation.  ...             history results citation\n",
            "\n",
            "[148 rows x 14 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V54NEpWF5o3z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "d3ecd006-9fdd-485c-ad6b-867e46e30d33"
      },
      "source": [
        "#Spelling Correction\n",
        "\n",
        "from textblob import TextBlob\n",
        "input_data['corrected spelling'] = input_data['removed rare words'].apply(lambda x: str(TextBlob(x).correct()))\n",
        "print(input_data)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Text  ...                    corrected spelling\n",
            "0                                           5 Ala. 740  ...                             5 all 740\n",
            "1                            Supreme Court of Alabama.  ...                       supreme alabama\n",
            "2                                                ADAMS  ...                                 adams\n",
            "3                                                   v.  ...                                      \n",
            "4                                   TANNER AND HORTON.  ...                         manner norton\n",
            "..                                                 ...  ...                                   ...\n",
            "143            There are no Filings for this citation.  ...                      filing situation\n",
            "144                                 Negative Treatment  ...                    negative treatment\n",
            "145  There are no Negative Treatment results for th...  ...  negative treatment results situation\n",
            "146                                            History  ...                               history\n",
            "147    There are no History results for this citation.  ...             history results situation\n",
            "\n",
            "[148 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL94R9SV5zVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "e8a7f36a-9e96-4f43-e5c3-9960e2e4a1b4"
      },
      "source": [
        "#Tokenization Data\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "input_data['tokenized data'] = input_data['corrected spelling'].apply(lambda x: TextBlob(x).words)\n",
        "print(input_data)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "                                                  Text  ...                             tokenized data\n",
            "0                                           5 Ala. 740  ...                              [5, all, 740]\n",
            "1                            Supreme Court of Alabama.  ...                         [supreme, alabama]\n",
            "2                                                ADAMS  ...                                    [adams]\n",
            "3                                                   v.  ...                                         []\n",
            "4                                   TANNER AND HORTON.  ...                           [manner, norton]\n",
            "..                                                 ...  ...                                        ...\n",
            "143            There are no Filings for this citation.  ...                        [filing, situation]\n",
            "144                                 Negative Treatment  ...                      [negative, treatment]\n",
            "145  There are no Negative Treatment results for th...  ...  [negative, treatment, results, situation]\n",
            "146                                            History  ...                                  [history]\n",
            "147    There are no History results for this citation.  ...              [history, results, situation]\n",
            "\n",
            "[148 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER00CJjV58fF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "7ed84d50-92dd-4581-9455-614d324b1161"
      },
      "source": [
        "#Stemming Data\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "input_data['Stemming'] = input_data['tokenized data'].apply(lambda x: \" \".join([st.stem(word) for word in x]))\n",
        "print(input_data)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  Text  ...                     Stemming\n",
            "0                                           5 Ala. 740  ...                    5 all 740\n",
            "1                            Supreme Court of Alabama.  ...               suprem alabama\n",
            "2                                                ADAMS  ...                         adam\n",
            "3                                                   v.  ...                             \n",
            "4                                   TANNER AND HORTON.  ...                manner norton\n",
            "..                                                 ...  ...                          ...\n",
            "143            There are no Filings for this citation.  ...                  file situat\n",
            "144                                 Negative Treatment  ...                neg treatment\n",
            "145  There are no Negative Treatment results for th...  ...  neg treatment result situat\n",
            "146                                            History  ...                      histori\n",
            "147    There are no History results for this citation.  ...        histori result situat\n",
            "\n",
            "[148 rows x 17 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHBmCCjs6WIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "ea51a56f-f078-48d9-e7fb-0fddc718692c"
      },
      "source": [
        "#Lemmatization\n",
        "\n",
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "input_data['Lemmatization'] = input_data['Stemming'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "print(input_data)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "                                                  Text  ...                Lemmatization\n",
            "0                                           5 Ala. 740  ...                    5 all 740\n",
            "1                            Supreme Court of Alabama.  ...               suprem alabama\n",
            "2                                                ADAMS  ...                         adam\n",
            "3                                                   v.  ...                             \n",
            "4                                   TANNER AND HORTON.  ...                manner norton\n",
            "..                                                 ...  ...                          ...\n",
            "143            There are no Filings for this citation.  ...                  file situat\n",
            "144                                 Negative Treatment  ...                neg treatment\n",
            "145  There are no Negative Treatment results for th...  ...  neg treatment result situat\n",
            "146                                            History  ...                      histori\n",
            "147    There are no History results for this citation.  ...        histori result situat\n",
            "\n",
            "[148 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziOI-qwR6lpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving Data to CSV\n",
        "\n",
        "input_data.to_csv('output.csv',index=False)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d1THOMu6wGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "4ff1957a-1624-4532-8c34-7364f30fff0b"
      },
      "source": [
        "#Calculation Of Term Frequencies\n",
        "\n",
        "term_frequencies = (input_data['Lemmatization']).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
        "term_frequencies.columns = ['words','term_frequency']\n",
        "term_frequencies"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>term_frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>all</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>740</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>suprem</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>alabama</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700</th>\n",
              "      <td>yield</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701</th>\n",
              "      <td>render</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>702</th>\n",
              "      <td>file</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>703</th>\n",
              "      <td>neg</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>704</th>\n",
              "      <td>histori</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>705 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       words  term_frequency\n",
              "0        all            17.0\n",
              "1          5             8.0\n",
              "2        740             2.0\n",
              "3     suprem             1.0\n",
              "4    alabama             1.0\n",
              "..       ...             ...\n",
              "700    yield             1.0\n",
              "701   render             1.0\n",
              "702     file             2.0\n",
              "703      neg             2.0\n",
              "704  histori             2.0\n",
              "\n",
              "[705 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS-wlBBB7OyE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "88faa3d6-8a45-4745-d63d-a44407013dd2"
      },
      "source": [
        "#TOP-10 : One-grams,Bi-grams,Tri-grams \n",
        "\n",
        "import itertools\n",
        "import collections\n",
        "from nltk import ngrams\n",
        "words = []\n",
        "for i in input_data['Lemmatization']:\n",
        "  words.append(nltk.tokenize.word_tokenize(i))\n",
        "data = [x for x in words if x != []]\n",
        "iter_values = list(itertools.chain.from_iterable(data))\n",
        "gram1 = ngrams(iter_values, 1)\n",
        "print(\"1 grams\")\n",
        "print(collections.Counter(gram1).most_common(10))\n",
        "print(\"Bi grams\")\n",
        "distributions = nltk.FreqDist(nltk.bigrams(iter_values))\n",
        "print(distributions.most_common(10))\n",
        "print(\"Tri grams\")\n",
        "distributions = nltk.FreqDist(nltk.trigrams(iter_values))\n",
        "print(distributions.most_common(10))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 grams\n",
            "[(('law',), 18), (('all',), 17), (('grow',), 17), (('contract',), 16), (('rep',), 16), (('plaintiff',), 15), (('posse',), 14), (('attach',), 14), (('cotton',), 14), (('2',), 13)]\n",
            "Bi grams\n",
            "[(('common', 'law'), 7), (('john', 'rep'), 6), (('tri', 'hon'), 6), (('fieri', 'facial'), 5), (('while', 'foot'), 4), (('can', 'not'), 4), (('appeal', 'circuit'), 4), (('error', 'circuit'), 3), (('attach', 'favor'), 3), (('allen', 'harrison'), 3)]\n",
            "Tri grams\n",
            "[(('2', 'john', 'rep'), 3), (('all', 'grover', 'convers'), 3), (('5', 'all', '740'), 2), (('writ', 'error', 'circuit'), 2), (('interest', 'vest', 'posse'), 2), (('vest', 'posse', 'either'), 2), (('posse', 'either', 'immedi'), 2), (('either', 'immedi', 'futur'), 2), (('immedi', 'futur', 'time'), 2), (('case', 'cite', 'headnot'), 2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BBiC4E_kefvV"
      },
      "source": [
        "# 2. Python Regular Expression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z1QJ-UwCenvN"
      },
      "source": [
        "## 2.1 Write a Python program to remove leading zeros from an IP address. (4 points)\n",
        "\n",
        "ip = \"260.08.094.109\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wSv6fVhOfFmv",
        "colab": {}
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "import re"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFGMdRvFcPxa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06c95743-66d2-44da-ede4-c1f8d423d14c"
      },
      "source": [
        "ip =  \"260.08.094.109\"\n",
        "zeros_removal = \".\".join([str(int(i)) for i in ip.split(\".\")])   \n",
        "print(zeros_removal)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "260.8.94.109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXRjaHzrfKAy"
      },
      "source": [
        "## 2.2 Write a Python Program to extract all the years from the following sentence. (4 points)\n",
        "\n",
        "sentence = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7xdJpDx9gjbX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5257ed4f-3737-46e9-dc88-e7aa5a95852a"
      },
      "source": [
        "sentence_given = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump.\"\n",
        "extracted_years = re.findall(r'2\\d\\d\\d', sentence_given)\n",
        "print(extracted_years)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['2010', '2010', '2019']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8p8zDUrcuiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}