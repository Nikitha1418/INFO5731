{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "In_class_exercise_09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikitha1418/INFO5731/blob/master/In_class_exercise_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEHj73LiJFkJ"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 11/11/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEYBxYFmJFkQ"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/INFO5731_FALL2020/blob/master/In_class_exercise/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-UWFzYcLgAz"
      },
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from textblob import Word\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, KFold, cross_val_score\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gsJF83oJFkV"
      },
      "source": [
        "\n",
        "\n",
        "train_df=pd.read_fwf(\"/content/stsa-train.txt\", header=None)\n",
        "train_df= pd.DataFrame(my_data_train)\n",
        "train_df = train_df.rename(columns={0: \"Sentiment\", 1: \"Text\"})\n",
        "test_df = pd.read_fwf(\"/content/stsa-test.txt\", header=None)\n",
        "test_df =  pd.DataFrame(my_data_test)\n",
        "test_df = test_df.rename(columns={0: \"Sentiment\", 1: \"Text\"})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGCTidEKMTCZ"
      },
      "source": [
        "#Removal of special characters:\n",
        "\n",
        "train_df['Cleaned_Data'] = train_df['Text'].apply(lambda x: ''.join(re.sub(r\"[^a-zA-Z0-9]+\", ' ', charctr) for charctr in x ))\n",
        "\n",
        "#Removal of punctuations :\n",
        "\n",
        "train_df['Cleaned_Data'] = train_df['Cleaned_Data'].str.replace('[^\\w\\s]','')\n",
        "\n",
        "train_df['Cleaned_Data'] = train_df['Cleaned_Data'].apply(lambda x :x.lower())\n",
        "\n",
        "#Removing stopwords by using stopwordslist\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "train_df['Cleaned_Data'] = train_df['Cleaned_Data'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ns53a_AZ9th",
        "outputId": "1c639e3a-8235-4e29-c632-0121da80faca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# from textblob import TextBlob\n",
        "nltk.download('punkt')\n",
        "train_df['Cleaned_Data'] = train_df['Cleaned_Data'].apply(lambda x: TextBlob(x).words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXCXBODWPMFZ",
        "outputId": "40aeb9cf-7361-4cca-eee0-efd56a3dbafe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "train_df['Cleaned_Data'] = train_df['Cleaned_Data'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az451QoGd4rL"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "train_tfidf_vect = TfidfVectorizer(analyzer = 'word')\n",
        "X_data = train_tfidf_vect.fit_transform(train_df['Cleaned_Data'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J64iWddQTRo"
      },
      "source": [
        "x_train_data, x_validation_data, y_train_data, y_validation_data = train_test_split(X_data, train_df['Sentiment'],test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcW2lOs0QqQk"
      },
      "source": [
        "test_df['Cleaned_Data'] = test_df['Text'].apply(lambda x: ''.join(re.sub(r\"[^a-zA-Z0-9]+\", ' ', charctr) for charctr in x ))\n",
        "\n",
        "#Removal of punctuations :\n",
        "\n",
        "test_df['Cleaned_Data'] = test_df['Cleaned_Data'].str.replace('[^\\w\\s]','')\n",
        "\n",
        "test_df['Cleaned_Data'] = test_df['Cleaned_Data'].apply(lambda x : x.lower())\n",
        "\n",
        "#Removing stopwords by using stopwordslist\n",
        "stop = stopwords.words('english')\n",
        "test_df['Cleaned_Data'] = test_df['Cleaned_Data'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e23lwgcrRD8I",
        "outputId": "a06f2b5e-7853-4c21-d0d1-885050ac43f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from textblob import TextBlob\n",
        "nltk.download('punkt')\n",
        "test_df['Cleaned_Data'] = test_df['Cleaned_Data'].apply(lambda x: TextBlob(x).words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwEMcqLjRKvL",
        "outputId": "45b38fd3-ae41-41dd-d8e9-998ef446b347",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "test_df['Cleaned_Data'] = test_df['Cleaned_Data'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc2BVRK7RZIb"
      },
      "source": [
        "test_tfidf_vect1 = TfidfVectorizer(analyzer = 'word', vocabulary = train_tfidf_vect.vocabulary_)\n",
        "test_tfidf_vect1.fit(test_df['Cleaned_Data'])\n",
        "x_test_data = test_tfidf_vect1.transform(test_df['Cleaned_Data'])\n",
        "y_test_data = test_df['Sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdjBUBsfSy-v",
        "outputId": "6e784cfe-12f4-4ce1-a44e-5a09cb80d657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Multinomial-Model\n",
        "multinomial_model = MultinomialNB()\n",
        "multinomial_model.fit(x_train_data, y_train_data)\n",
        "validation_predicted_mnb = multinomial_model.predict(x_validation_data)\n",
        "validation_accuracy_mnb = round(accuracy_score(validation_predicted_mnb,y_validation_data),4)*100\n",
        "print(\"Validation Data\")\n",
        "print(\"Accuracy - \", validation_accuracy_mnb)\n",
        "print(classification_report(y_validation_data, validation_predicted_mnb))\n",
        "kfold = KFold(10, random_state = 7, shuffle=True)\n",
        "scoring = 'accuracy'\n",
        "print(\"Corss Validation Score - \", round(cross_val_score(multinomial_model, x_test_data, y_test_data, cv=kfold).mean()*100,3))\n",
        "test_predicted_mnb = multinomial_model.predict(x_test_data)\n",
        "test_accuracy_mnb = round(accuracy_score(test_predicted_mnb, y_test_data),4)*100\n",
        "print(\"Testing Data\")\n",
        "print(\"Accuracy - \", test_accuracy_mnb)\n",
        "print(classification_report(y_test_data, test_predicted_mnb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Data\n",
            "Accuracy -  77.53\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.67      0.75       695\n",
            "           1       0.73      0.88      0.80       689\n",
            "\n",
            "    accuracy                           0.78      1384\n",
            "   macro avg       0.79      0.78      0.77      1384\n",
            "weighted avg       0.79      0.78      0.77      1384\n",
            "\n",
            "Corss Validation Score -  72.105\n",
            "Testing Data\n",
            "Accuracy -  78.75\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.68      0.76       912\n",
            "           1       0.74      0.89      0.81       909\n",
            "\n",
            "    accuracy                           0.79      1821\n",
            "   macro avg       0.80      0.79      0.79      1821\n",
            "weighted avg       0.80      0.79      0.79      1821\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnor2iyXc6qu",
        "outputId": "e7138ee3-bd96-4a57-bfe4-1b87aeb06aab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#svm-Model\n",
        "\n",
        "svm_model = LinearSVC()\n",
        "svm_model.fit(x_train_data, y_train_data)\n",
        "validation_predicted_svm = svm_model.predict(x_validation_data)\n",
        "validation_accuracy_svm = round(accuracy_score(validation_predicted_svm,y_validation_data),4)*100\n",
        "print(\"Validation Data\")\n",
        "print(\"Accuracy - \", validation_accuracy_svm)\n",
        "print(classification_report(y_validation_data, validation_predicted_svm))\n",
        "kfold = KFold(10, random_state = 7, shuffle=True)\n",
        "scoring = 'accuracy'\n",
        "print(\"Corss Validation Score - \", round(cross_val_score(svm_model, x_test_data, y_test_data, cv=kfold).mean()*100,3))\n",
        "test_predicted_svm = svm_model.predict(x_test_data)\n",
        "test_accuracy_svm = round(accuracy_score(test_predicted_svm, y_test_data),4)*100\n",
        "print(\"Testing Data\")\n",
        "print(\"Accuracy - \", test_accuracy_svm)\n",
        "print(classification_report(y_test_data, test_predicted_svm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Data\n",
            "Accuracy -  76.73\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.74      0.76       695\n",
            "           1       0.75      0.80      0.77       689\n",
            "\n",
            "    accuracy                           0.77      1384\n",
            "   macro avg       0.77      0.77      0.77      1384\n",
            "weighted avg       0.77      0.77      0.77      1384\n",
            "\n",
            "Corss Validation Score -  70.568\n",
            "Testing Data\n",
            "Accuracy -  78.47\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.75      0.78       912\n",
            "           1       0.77      0.82      0.79       909\n",
            "\n",
            "    accuracy                           0.78      1821\n",
            "   macro avg       0.79      0.78      0.78      1821\n",
            "weighted avg       0.79      0.78      0.78      1821\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFSY88hnebAB",
        "outputId": "f85242a2-47f8-4e8d-fc2d-75978710c804",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#KNN-Model\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors = 10)\n",
        "knn_model.fit(x_train_data, y_train_data)\n",
        "validation_predicted_knn = knn_model.predict(x_validation_data)\n",
        "validation_accuracy_knn = round(accuracy_score(validation_predicted_knn, y_validation_data),4)*100\n",
        "print(\"Validation Data\")\n",
        "print(\"Accuracy - \", validation_accuracy_knn)\n",
        "print(classification_report(y_validation_data, validation_predicted_knn))\n",
        "kfold = KFold(10, random_state = 7, shuffle=True)\n",
        "scoring = 'accuracy'\n",
        "print(\"Corss Validation Score - \", round(cross_val_score(knn_model, x_test_data, y_test_data, cv=kfold).mean()*100,3))\n",
        "test_predicted_knn = knn_model.predict(x_test_data)\n",
        "test_accuracy_knn = round(accuracy_score(test_predicted_knn, y_test_data),4)*100\n",
        "print(\"Testing Data\")\n",
        "print(\"Accuracy - \", test_accuracy_knn)\n",
        "print(classification_report(y_test_data, test_predicted_knn))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Data\n",
            "Accuracy -  61.56\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.91      0.70       695\n",
            "           1       0.77      0.32      0.45       689\n",
            "\n",
            "    accuracy                           0.62      1384\n",
            "   macro avg       0.67      0.61      0.58      1384\n",
            "weighted avg       0.67      0.62      0.58      1384\n",
            "\n",
            "Corss Validation Score -  54.638\n",
            "Testing Data\n",
            "Accuracy -  60.85\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.91      0.70       912\n",
            "           1       0.77      0.30      0.44       909\n",
            "\n",
            "    accuracy                           0.61      1821\n",
            "   macro avg       0.67      0.61      0.57      1821\n",
            "weighted avg       0.67      0.61      0.57      1821\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isPCDCjxh_Mb",
        "outputId": "aa39ab25-231e-4480-bf86-e3466cf896b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#DecisionTree\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(x_train_data, y_train_data)\n",
        "validation_predicted_dt = dt_model.predict(x_validation_data)\n",
        "validation_accuracy_dt = round(accuracy_score(validation_predicted_dt, y_validation_data),4)*100\n",
        "print(\"Validation Data\")\n",
        "print(\"Accuracy - \", validation_accuracy_dt)\n",
        "print(classification_report(y_validation_data, validation_predicted_dt))\n",
        "kfold = KFold(10, random_state = 7, shuffle=True)\n",
        "scoring = 'accuracy'\n",
        "print(\"Corss Validation Score - \", round(cross_val_score(dt_model, x_test_data, y_test_data, cv=kfold).mean()*100,3))\n",
        "test_predicted_dt = dt_model.predict(x_test_data)\n",
        "test_accuracy_dt = round(accuracy_score(test_predicted_dt, y_test_data),4)*100\n",
        "print(\"Testing Data\")\n",
        "print(\"Accuracy - \", test_accuracy_dt)\n",
        "print(classification_report(y_test_data, test_predicted_dt))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Data\n",
            "Accuracy -  65.97\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.68      0.67       695\n",
            "           1       0.67      0.64      0.65       689\n",
            "\n",
            "    accuracy                           0.66      1384\n",
            "   macro avg       0.66      0.66      0.66      1384\n",
            "weighted avg       0.66      0.66      0.66      1384\n",
            "\n",
            "Corss Validation Score -  60.954\n",
            "Testing Data\n",
            "Accuracy -  66.01\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.68      0.67       912\n",
            "           1       0.67      0.64      0.65       909\n",
            "\n",
            "    accuracy                           0.66      1821\n",
            "   macro avg       0.66      0.66      0.66      1821\n",
            "weighted avg       0.66      0.66      0.66      1821\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf0BWK5biWma",
        "outputId": "8dbf679c-487f-4b18-fb85-f20e288710a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#RandomForest- Classifier\n",
        "\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(x_train_data, y_train_data)\n",
        "validation_predicted_rf = rf_model.predict(x_validation_data)\n",
        "validation_accuracy_rf = round(accuracy_score(validation_predicted_rf, y_validation_data),4)*100\n",
        "print(\"Validation Data\")\n",
        "print(\"Accuracy - \", validation_accuracy_rf)\n",
        "print(classification_report(y_validation_data, validation_predicted_rf))\n",
        "kfold = KFold(10, random_state = 7, shuffle=True)\n",
        "scoring = 'accuracy'\n",
        "print(\"Corss Validation Score - \", round(cross_val_score(rf_model, x_test_data, y_test_data, cv=kfold).mean()*100,3))\n",
        "test_predicted_rf = rf_model.predict(x_test_data)\n",
        "test_accuracy_rf = round(accuracy_score(test_predicted_rf, y_test_data),4)*100\n",
        "print(\"Testing Data\")\n",
        "print(\"Accuracy - \", test_accuracy_rf)\n",
        "print(classification_report(y_test_data, test_predicted_rf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Data\n",
            "Accuracy -  72.25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.69      0.71       695\n",
            "           1       0.71      0.76      0.73       689\n",
            "\n",
            "    accuracy                           0.72      1384\n",
            "   macro avg       0.72      0.72      0.72      1384\n",
            "weighted avg       0.72      0.72      0.72      1384\n",
            "\n",
            "Corss Validation Score -  65.733\n",
            "Testing Data\n",
            "Accuracy -  73.31\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.72      0.73       912\n",
            "           1       0.73      0.75      0.74       909\n",
            "\n",
            "    accuracy                           0.73      1821\n",
            "   macro avg       0.73      0.73      0.73      1821\n",
            "weighted avg       0.73      0.73      0.73      1821\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxJNQH-Nitap",
        "outputId": "05f069b4-5343-494e-814d-8731f11aac97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#XGB-Classifier\n",
        "\n",
        "xgb_model = XGBClassifier()\n",
        "xgb_model.fit(x_train_data, y_train_data)\n",
        "validation_predicted_xgb = xgb_model.predict(x_validation_data)\n",
        "validation_accuracy_xgb = round(accuracy_score(validation_predicted_xgb, y_validation_data),4)*100\n",
        "print(\"Validation Data\")\n",
        "print(\"Accuracy - \", validation_accuracy_xgb)\n",
        "print(classification_report(y_validation_data, validation_predicted_xgb))\n",
        "kfold = KFold(10, random_state = 7, shuffle=True)\n",
        "scoring = 'accuracy'\n",
        "print(\"Corss Validation Score - \", round(cross_val_score(xgb_model, x_test_data, y_test_data, cv=kfold).mean()*100,3))\n",
        "test_predicted_xgb = xgb_model.predict(x_test_data)\n",
        "test_accuracy_xgb = round(accuracy_score(test_predicted_xgb, y_test_data),4)*100\n",
        "print(\"Testing Data\")\n",
        "print(\"Accuracy - \", test_accuracy_xgb)\n",
        "print(classification_report(y_test_data, test_predicted_xgb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Data\n",
            "Accuracy -  61.78\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.35      0.48       695\n",
            "           1       0.58      0.88      0.70       689\n",
            "\n",
            "    accuracy                           0.62      1384\n",
            "   macro avg       0.67      0.62      0.59      1384\n",
            "weighted avg       0.67      0.62      0.59      1384\n",
            "\n",
            "Corss Validation Score -  62.052\n",
            "Testing Data\n",
            "Accuracy -  63.21\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.39      0.51       912\n",
            "           1       0.59      0.88      0.70       909\n",
            "\n",
            "    accuracy                           0.63      1821\n",
            "   macro avg       0.67      0.63      0.61      1821\n",
            "weighted avg       0.67      0.63      0.61      1821\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry0YMIxU-8Ql"
      },
      "source": [
        "Accuracies:\n",
        "\n",
        "MultinomialNB - 78.75%\n",
        "SVM - 78.47%\n",
        "KNN - 60.85%\n",
        "Decision Tree - 66.01%\n",
        "Random Forest - 73.31%\n",
        "XG Boost - 63.21%"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}